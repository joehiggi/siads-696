{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b7e1f07",
   "metadata": {},
   "source": [
    "# Foreign Exchange Return Forecasting of Neighboring Countries based on Powerful Anchor Countries\n",
    "# *SIADS 696: Milestone II*\n",
    "\n",
    "### *By Team #2*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cfa692",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "*Our team studied the impact on foreign exchange returns between neighboring countries and anchoring countries (neighboring countries with a larger GDP). We studied:*\n",
    "\n",
    "`H_0` (null): Anchoring country foreign exchange return rates have no impact on foreign exchange return rates of neighboring countries.\n",
    "\n",
    "`H_1` (alternative): Anchoring country foreign exchange return rates have impact on foreign exchange return rates of neighboring countries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db71ed23",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "```\n",
    ".\n",
    "├── data\n",
    "│   ├── input\n",
    "│   └── output\n",
    "├── docs\n",
    "├── logs\n",
    "└── src\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bd59bc",
   "metadata": {},
   "source": [
    "## Sections\n",
    "- Defining Custom Functions\n",
    "- Importing Data\n",
    "- Applying Unsupervised Learning\n",
    "- Applying Supervised Learning\n",
    "    - Granger Causality\n",
    "    - Linear Regression\n",
    "    - XGBoost\n",
    "    - KNN\n",
    "- Testing Model Performance\n",
    "    - Performing Ablation\n",
    "    - Performing Feature Importance\n",
    "- Visualization\n",
    "- Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d725be9e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a791312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Packages\n",
    "import country_converter as coco\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import csv\n",
    "import re\n",
    "\n",
    "# Importing partial packages\n",
    "from sklearn.metrics import (\n",
    "    root_mean_squared_error,\n",
    "    silhouette_score,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    f1_score,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    GridSearchCV,\n",
    "    cross_val_score,\n",
    "    ValidationCurveDisplay,\n",
    ")\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from utility import create_lag, load_data\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1642f924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignoring unnecessary warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Showing all rows\n",
    "# pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5c3aa1",
   "metadata": {},
   "source": [
    "## Defining Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ca5105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing column names to standardize\n",
    "def standardize_column_names(dataframe):\n",
    "    dataframe.columns = [\n",
    "        str(column).lower().replace(\" \", \"_\").replace(\",\", \"\")\n",
    "        for column in dataframe.columns\n",
    "    ]\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a9ae81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xxxusd(code):\n",
    "    x = f\"{code}USD=X\", f\"USD{code}=X\"\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b813ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing functions\n",
    "def clean(country):\n",
    "    if pd.isna(country):\n",
    "        return country\n",
    "    country = str(country).strip()\n",
    "    country = p.sub(\"\", country)\n",
    "    return re.sub(r\",\\s*The$\", \"\", country, flags=re.I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bd2830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing functions\n",
    "def short(country):\n",
    "    if pd.isna(country):\n",
    "        return pd.NA\n",
    "    res = cc.convert(names=clean(country), to=\"name_short\")\n",
    "    if isinstance(res, (list, tuple)):\n",
    "        res = res[0] if res else pd.NA\n",
    "    if not res or res == \"not found\" or pd.isna(res):\n",
    "        warnings.warn(f\"Problem: {country}\")\n",
    "        return pd.NA\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb285939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Granger causality function\n",
    "def granger(res, g, ml=5, a=0.05):\n",
    "    x = []\n",
    "    for i, j in g.items():\n",
    "        for k in j:\n",
    "            if i not in res.columns or k not in res.columns:\n",
    "                continue\n",
    "            df = pd.concat([res[k], res[i]], axis=1).dropna()\n",
    "            df.columns = [\"neighbor\", \"anchor\"]\n",
    "            if len(df) <= ml * 3:\n",
    "                continue\n",
    "            t = grangercausalitytests(df, maxlag=ml)\n",
    "            pval = [t[lag][0][\"ssr_ftest\"][1] for lag in range(1, ml + 1)]\n",
    "            min_p = float(np.min(pval))\n",
    "            best_lag = int(np.argmin(pval) + 1)\n",
    "            x.append(\n",
    "                {\n",
    "                    \"anchor\": i,\n",
    "                    \"neighbor\": k,\n",
    "                    \"min_pval\": round(min_p, 4),\n",
    "                    \"best_lag (days)\": best_lag,\n",
    "                    \"significant\": (min_p < a),\n",
    "                }\n",
    "            )\n",
    "    rdf = pd.DataFrame(x)\n",
    "    return rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33e16f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lag(neighbor, dataframe):\n",
    "    # Create lag features (e.g., previous 5 days' returns)\n",
    "    for i in range(1, 25):\n",
    "        dataframe[f\"return_lag_{i}\"] = dataframe[neighbor].pct_change().shift(i)\n",
    "\n",
    "    # Create moving average features\n",
    "    dataframe[\"MA_30\"] = dataframe[neighbor].rolling(window=30).mean().shift(1)\n",
    "    dataframe[\"MA_60\"] = dataframe[neighbor].rolling(window=60).mean().shift(1)\n",
    "    dataframe[\"MA_90\"] = dataframe[neighbor].rolling(window=90).mean().shift(1)\n",
    "\n",
    "    # Drop initial rows with NaNs created by rolling windows\n",
    "    dataframe.dropna(inplace=True)\n",
    "    dataframe = dataframe.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0309541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this for the neighbor alone: control\n",
    "# Run this for the anchor + neighbor: treatment\n",
    "def perform_xgb_for_anchor_neighbor(neighbor, dataframe):\n",
    "    # Starting with CNY/CDF as an example\n",
    "    dataframe[\"target\"] = dataframe[neighbor].shift(-1)\n",
    "\n",
    "    # Define features (X) and target (y)\n",
    "    features = [\n",
    "        col\n",
    "        for col in dataframe.columns\n",
    "        if col == neighbor or col.startswith(\"MA_\") or col.startswith(\"return_lag_\")\n",
    "    ]\n",
    "    X = dataframe[features]\n",
    "    y = dataframe[\"target\"]\n",
    "\n",
    "    # Time-based train-test split\n",
    "    split_index = int(len(X) * 0.8)\n",
    "    X_train, X_test = X[:split_index], X[split_index:]\n",
    "    y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "    xgb_0 = xgb.XGBRegressor()\n",
    "    parameters = {\n",
    "        \"nthread\": [4],\n",
    "        \"objective\": [\"reg:squarederror\"],\n",
    "        \"learning_rate\": [0.08, 0.15, 0.3],\n",
    "        \"max_depth\": [2, 4, 8],\n",
    "        \"min_child_weight\": [4],\n",
    "        \"subsample\": [0.2, 0.5, 0.8],\n",
    "        \"colsample_bytree\": [0.7],\n",
    "        \"n_estimators\": [2, 5, 10],\n",
    "    }\n",
    "\n",
    "    xgb_grid = GridSearchCV(xgb_0, parameters, cv=2, n_jobs=5, verbose=True)\n",
    "    xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "    return xgb_grid.best_score_, xgb_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9e6d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide best lag\n",
    "def mlag(df, col, lag):\n",
    "    for k in range(1, lag + 1):\n",
    "        df[f\"{col}_lag{k}\"] = df[col].shift(k)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b03401",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc415f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Real GDP Purchasing Power Parity\n",
    "# Note the Ranking; 1 = big country per region\n",
    "country_gdp = pd.read_csv(\"../data/input/real_gdp_purchasing_power_parity_0.csv\")\n",
    "\n",
    "# Displaying the first 5 rows of the dataframe\n",
    "country_gdp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e8d946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Fred Anchors\n",
    "df_fred_world_gdp = pd.read_csv(\"../data/input/fred_anchors_0.csv\")\n",
    "\n",
    "# Preprocessing Fred Anchors\n",
    "df_fred_world_gdp[\"observation_date\"] = pd.to_datetime(\n",
    "    df_fred_world_gdp[\"observation_date\"]\n",
    ")\n",
    "df_fred_world_gdp[\"time_period\"] = df_fred_world_gdp[\"observation_date\"].dt.year\n",
    "df_fred_world_gdp = df_fred_world_gdp.drop(columns=[\"observation_date\"]).rename(\n",
    "    columns={\"NYGDPMKTPCDWLD\": \"world_gdp\"}\n",
    ")\n",
    "\n",
    "# Displaying the first 5 rows of the dataframe\n",
    "df_fred_world_gdp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d496e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing GDP\n",
    "df_imf_gdp = pd.read_csv(\n",
    "    \"../data/input/imf_gdp_0.csv\",\n",
    "    on_bad_lines=\"skip\",\n",
    "    sep=\",\",\n",
    "    quoting=csv.QUOTE_ALL,\n",
    "    skipinitialspace=True,\n",
    "    usecols=[\n",
    "        \"COUNTRY\",\n",
    "        \"TIME_PERIOD\",\n",
    "        \"TYPE_OF_TRANSFORMATION\",\n",
    "        \"FREQUENCY\",\n",
    "        \"OBS_VALUE\",\n",
    "        \"INDICATOR\",\n",
    "    ],\n",
    "    engine=\"python\",\n",
    ")\n",
    "\n",
    "# Preprocessing GDP\n",
    "df_imf_gdp = (\n",
    "    standardize_column_names(df_imf_gdp)\n",
    "    .query(\n",
    "        \"indicator == 'US Dollar per domestic currency' \"\n",
    "        \"and type_of_transformation == 'End-of-period (EoP)' \"\n",
    "        \"and frequency == 'Annual'\"\n",
    "    )\n",
    "    .dropna(subset=[\"obs_value\"])\n",
    "    .rename(columns={\"time_period\": \"year\"})\n",
    "    .assign(year=lambda d: d[\"year\"].str[:4])\n",
    "    .sort_values([\"country\", \"year\"])\n",
    "    .drop(columns=[\"indicator\", \"type_of_transformation\", \"frequency\"])\n",
    "    .reset_index(drop=True)\n",
    ").assign(year=lambda d: pd.to_datetime(d[\"year\"], errors=\"coerce\").dt.year)\n",
    "\n",
    "# Displaying the first 5 rows of the dataframe\n",
    "df_imf_gdp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5d450d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Exchange Rates\n",
    "df_imf_trade = pd.read_csv(\n",
    "    \"../data/input/imf_trade_0.csv\",\n",
    "    usecols=[\n",
    "        \"COUNTRY\",\n",
    "        \"COUNTERPART_COUNTRY\",\n",
    "        \"TIME_PERIOD\",\n",
    "        \"OBS_VALUE\",\n",
    "        \"TRADE_FLOW\",\n",
    "        \"SCALE\",\n",
    "        \"UNIT\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Manually excluding countries that are either trade in pegged currencies or don't have a true boundary from another\n",
    "ls_0 = [\n",
    "    \"World\",\n",
    "    \"Advanced Economies\",\n",
    "    \"Latin America and the Caribbean (LAC)\",\n",
    "    \"Hong Kong Special Administrative Region, People's Republic of China\",\n",
    "    \"Emerging and Developing Europe\",\n",
    "    \"Middle East and Central Asia\",\n",
    "    \"Emerging Market and Developing Economies\",\n",
    "    \"Euro Area (EA)\",\n",
    "    \"Emerging and Developing Asia\",\n",
    "]\n",
    "\n",
    "# Excluding the \"Exclusion List\"\n",
    "df_imf_trade = df_imf_trade[\n",
    "    (~df_imf_trade[\"COUNTRY\"].isin(ls_0))\n",
    "    & (~df_imf_trade[\"COUNTERPART_COUNTRY\"].isin(ls_0))\n",
    "]\n",
    "\n",
    "# Viewing first five rows\n",
    "df_imf_trade = standardize_column_names(df_imf_trade).sort_values(\n",
    "    by=[\"obs_value\"], ascending=False\n",
    ")\n",
    "\n",
    "# Displaying the first 5 rows of the dataframe\n",
    "df_imf_trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465b43dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Exchange Rates\n",
    "cc = coco.CountryConverter()\n",
    "p = re.compile(\n",
    "    r\",\\s*(?:Kingdom of the Netherlands|United Kingdom-British Overseas Territory|Republic of the|Union of the|State of the)$\",\n",
    "    re.I,\n",
    ")\n",
    "\n",
    "# Defining countries with pegged currencies\n",
    "pegged = [\n",
    "    \"Aruba\",\n",
    "    \"The Bahamas\",\n",
    "    \"Bahrain\",\n",
    "    \"Barbados\",\n",
    "    \"Belize\",\n",
    "    \"Bermuda\",\n",
    "    \"Cayman Islands\",\n",
    "    \"Cuba\",\n",
    "    \"Djibouti\",\n",
    "    \"Antigua and Barbuda\",\n",
    "    \"Dominica\",\n",
    "    \"Grenada\",\n",
    "    \"Saint Kitts and Nevis\",\n",
    "    \"Saint Lucia\",\n",
    "    \"Saint Vincent and the Grenadines\",\n",
    "    \"El Salvador\",\n",
    "    \"Eritrea\",\n",
    "    \"Hong Kong\",\n",
    "    \"Jordan\",\n",
    "    \"Kuwait\",\n",
    "    \"Lebanon\",\n",
    "    \"Curaçao\",\n",
    "    \"Sint Maarten\",\n",
    "    \"Oman\",\n",
    "    \"Panama\",\n",
    "    \"Qatar\",\n",
    "    \"Saudi Arabia\",\n",
    "    \"United Arab Emirates\",\n",
    "    \"Venezuela\",\n",
    "]\n",
    "\n",
    "pegged = {short(x) for x in pegged}\n",
    "pegged.discard(pd.NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bda0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining countries in the European Union that use the Euro (EUR) and British Pound (GBP)\n",
    "EUR = [\n",
    "    \"Austria\",\n",
    "    \"Belgium\",\n",
    "    \"Cyprus\",\n",
    "    \"Estonia\",\n",
    "    \"Finland\",\n",
    "    \"France\",\n",
    "    \"Germany\",\n",
    "    \"Greece\",\n",
    "    \"Ireland\",\n",
    "    \"Italy\",\n",
    "    \"Latvia\",\n",
    "    \"Lithuania\",\n",
    "    \"Luxembourg\",\n",
    "    \"Malta\",\n",
    "    \"Netherlands\",\n",
    "    \"Portugal\",\n",
    "    \"Slovakia\",\n",
    "    \"Slovenia\",\n",
    "    \"Spain\",\n",
    "    \"Andorra\",\n",
    "    \"Monaco\",\n",
    "    \"San Marino\",\n",
    "    \"Vatican City\",\n",
    "    \"Saint Barthélemy\",\n",
    "    \"Saint Pierre and Miquelon\",\n",
    "    \"Kosovo\",\n",
    "    \"Montenegro\",\n",
    "    \"Bosnia and Herzegovina\",\n",
    "    \"Bulgaria\",\n",
    "    \"Cape Verde\",\n",
    "    \"Cameroon\",\n",
    "    \"Central African Republic\",\n",
    "    \"Chad\",\n",
    "    \"Republic of the Congo\",\n",
    "    \"Equatorial Guinea\",\n",
    "    \"Gabon\",\n",
    "    \"Benin\",\n",
    "    \"Burkina Faso\",\n",
    "    \"Côte d'Ivoire\",\n",
    "    \"Guinea-Bissau\",\n",
    "    \"Mali\",\n",
    "    \"Niger\",\n",
    "    \"Senegal\",\n",
    "    \"Togo\",\n",
    "    \"French Polynesia\",\n",
    "    \"New Caledonia\",\n",
    "    \"Wallis and Futuna\",\n",
    "    \"Comoros\",\n",
    "    \"Croatia\",\n",
    "    \"Morocco\",\n",
    "    \"São Tomé and Príncipe\",\n",
    "    \"Denmark\",\n",
    "    \"North Macedonia\",\n",
    "]\n",
    "\n",
    "# Defining countries that use the British Pound (GBP)\n",
    "GBP = [\n",
    "    \"Guernsey\",\n",
    "    \"Jersey\",\n",
    "    \"Isle of Man\",\n",
    "    \"Gibraltar\",\n",
    "    \"Falkland Islands\",\n",
    "    \"Saint Helena\",\n",
    "]\n",
    "\n",
    "# Defining other countries with pegged currencies or no true boundary\n",
    "other = [\n",
    "    \"Bhutan\",\n",
    "    \"Nepal\",\n",
    "    \"North Korea\",\n",
    "    \"Afghanistan\",\n",
    "    \"Turkmenistan\",\n",
    "    \"South Sudan\",\n",
    "    \"Guam\",\n",
    "    \"Macau\",\n",
    "    \"Tuvalu\",\n",
    "    \"Kiribati\",\n",
    "    \"Palau\",\n",
    "    \"Greenland\",\n",
    "    \"Maldives\",\n",
    "    \"Iraq\",\n",
    "    \"Solomon Islands\",\n",
    "    \"Brunei Darussalam\",\n",
    "    \"Bangladesh\",\n",
    "    \"Myanmar\",\n",
    "    \"Marshall Islands\",\n",
    "    \"Iran\",\n",
    "    \"Yemen\",\n",
    "    \"Libya\",\n",
    "    \"Somalia\",\n",
    "    \"Liberia\",\n",
    "    \"Sudan\",\n",
    "    \"Sierra Leone\",\n",
    "    \"Mongolia\",\n",
    "    \"Angola\",\n",
    "    \"Kyrgyz Republic\",\n",
    "    \"Tajikistan\",\n",
    "]\n",
    "\n",
    "# Cleaning country names\n",
    "EUR = {short(x) for x in EUR if pd.notna(short(x))}\n",
    "GBP = {short(x) for x in GBP if pd.notna(short(x))}\n",
    "other = {short(x) for x in other if pd.notna(short(x))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa99ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing cleaned data\n",
    "# TODO - where is this coming from?\n",
    "# I.e. what code created these files?\n",
    "df_trade = pd.read_parquet(\"../data/input/trade_0.parquet\")\n",
    "df_gdp = pd.read_parquet(\"../data/input/gdp_0.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379e13d9",
   "metadata": {},
   "source": [
    "## Applying Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327c560f",
   "metadata": {},
   "source": [
    "#### Determining Country Pairing and GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95afa563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting country names to short format\n",
    "cc = coco.CountryConverter()\n",
    "p = re.compile(\n",
    "    r\",\\s*(?:Kingdom of the Netherlands|United Kingdom-British Overseas Territory|Republic of the|Union of the|State of the)$\",\n",
    "    re.I,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6196915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anchors selection\n",
    "df_gdp = df_gdp[~(df_gdp[\"COUNTRY\"] == \"United States\")]\n",
    "df_gdp.head()\n",
    "Anchor = {\n",
    "    \"EUR\": EUR,\n",
    "    \"CNY\": {\"China\"},\n",
    "    \"JPY\": {\"Japan\"},\n",
    "}\n",
    "\n",
    "# No USD due to many relationship ties with multiple currency.\n",
    "# Time Period\n",
    "period = 10\n",
    "\n",
    "# N Neighbor\n",
    "n = 10\n",
    "\n",
    "# Minimum Percentage Volume\n",
    "v = 0.05\n",
    "\n",
    "# Exports of goods\n",
    "# Neighbor mapping\n",
    "neighbor = {x: i for i, y in Anchor.items() for x in y}\n",
    "ex = EUR | GBP | other | {\"China\", \"Japan\", \"United States\"}\n",
    "df_trade = df_trade.dropna(\n",
    "    subset=[\"COUNTRY\", \"COUNTERPART_COUNTRY\", \"TIME_PERIOD\", \"OBS_VALUE\"]\n",
    ").copy()\n",
    "\n",
    "# Keep data period\n",
    "df_trade = df_trade[df_trade[\"TIME_PERIOD\"].astype(str).str.match(r\"^\\d{4}\")]\n",
    "df_trade[\"year\"] = df_trade[\"TIME_PERIOD\"].astype(str).str[:4].astype(int)\n",
    "max_year = int(df_trade[\"year\"].max())\n",
    "df_trade = df_trade[df_trade[\"year\"].between(max_year - period + 1, max_year)]\n",
    "\n",
    "# Filter and map potential neighbors\n",
    "df_export = df_trade[~df_trade[\"COUNTRY\"].isin(ex)].copy()\n",
    "df_export[\"anchor\"] = df_export[\"COUNTERPART_COUNTRY\"].map(neighbor)\n",
    "\n",
    "# Total exports per country\n",
    "etot = (\n",
    "    df_export.groupby(\"COUNTRY\", as_index=False)[\"OBS_VALUE\"]\n",
    "    .sum()\n",
    "    .rename(columns={\"OBS_VALUE\": \"export_total\"})\n",
    ")\n",
    "\n",
    "# Exports to each anchor\n",
    "eanch = (\n",
    "    df_export.dropna(subset=[\"anchor\"])\n",
    "    .groupby([\"COUNTRY\", \"anchor\"], as_index=False)[\"OBS_VALUE\"]\n",
    "    .sum()\n",
    "    .rename(columns={\"OBS_VALUE\": \"export_to_anchor\"})\n",
    ")\n",
    "\n",
    "# Export shares\n",
    "esh = eanch.merge(etot, on=\"COUNTRY\", how=\"left\").assign(\n",
    "    export_share=lambda d: d[\"export_to_anchor\"] / d[\"export_total\"]\n",
    ")\n",
    "\n",
    "# Best export anchor per country\n",
    "bexp = esh.sort_values(\n",
    "    [\"COUNTRY\", \"export_share\", \"export_to_anchor\"], ascending=[True, False, False]\n",
    ").drop_duplicates(\"COUNTRY\")\n",
    "bexp = bexp[bexp[\"export_share\"] >= v]\n",
    "\n",
    "# Swap role\n",
    "df_import = df_trade.rename(\n",
    "    columns={\"COUNTRY\": \"COUNTERPART_COUNTRY_orig\", \"COUNTERPART_COUNTRY\": \"COUNTRY\"}\n",
    ").rename(columns={\"COUNTERPART_COUNTRY_orig\": \"COUNTERPART_COUNTRY\"})\n",
    "\n",
    "# Potential neighbors\n",
    "df_import = df_import[~df_import[\"COUNTRY\"].isin(ex)].copy()\n",
    "df_import[\"anchor\"] = df_import[\"COUNTERPART_COUNTRY\"].map(neighbor)\n",
    "\n",
    "# Total imports per country\n",
    "import_totals = (\n",
    "    df_import.groupby(\"COUNTRY\", as_index=False)[\"OBS_VALUE\"]\n",
    "    .sum()\n",
    "    .rename(columns={\"OBS_VALUE\": \"import_total\"})\n",
    ")\n",
    "\n",
    "# Imports from each anchor\n",
    "ianch = (\n",
    "    df_import.dropna(subset=[\"anchor\"])\n",
    "    .groupby([\"COUNTRY\", \"anchor\"], as_index=False)[\"OBS_VALUE\"]\n",
    "    .sum()\n",
    "    .rename(columns={\"OBS_VALUE\": \"import_from_anchor\"})\n",
    ")\n",
    "\n",
    "# Import shares\n",
    "ish = ianch.merge(import_totals, on=\"COUNTRY\", how=\"left\").assign(\n",
    "    import_share=lambda d: d[\"import_from_anchor\"] / d[\"import_total\"]\n",
    ")\n",
    "\n",
    "# Best import anchor per country\n",
    "bimp = ish.sort_values(\n",
    "    [\"COUNTRY\", \"import_share\", \"import_from_anchor\"], ascending=[True, False, False]\n",
    ").drop_duplicates(\"COUNTRY\")\n",
    "bimp = bimp[bimp[\"import_share\"] >= v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d77ff09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine table\n",
    "comb = esh.merge(ish, on=[\"COUNTRY\", \"anchor\"], how=\"outer\", suffixes=(\"_exp\", \"_imp\"))\n",
    "\n",
    "# Handle missing value\n",
    "f = [\n",
    "    \"export_to_anchor\",\n",
    "    \"export_total\",\n",
    "    \"export_share\",\n",
    "    \"import_from_anchor\",\n",
    "    \"import_total\",\n",
    "    \"import_share\",\n",
    "]\n",
    "for c in f:\n",
    "    if c not in comb.columns:\n",
    "        comb[c] = 0.0\n",
    "comb[f] = comb[f].fillna(0.0)\n",
    "\n",
    "# Combined metrics\n",
    "comb = comb.assign(\n",
    "    total_trade_with_anchor=lambda d: d[\"export_to_anchor\"] + d[\"import_from_anchor\"],\n",
    "    total_trade_volume=lambda d: d[\"export_total\"] + d[\"import_total\"],\n",
    ")\n",
    "comb[\"combined_exposure\"] = 0.0\n",
    "nz = comb[\"total_trade_volume\"] > 0\n",
    "comb.loc[nz, \"combined_exposure\"] = (\n",
    "    comb.loc[nz, \"total_trade_with_anchor\"] / comb.loc[nz, \"total_trade_volume\"]\n",
    ")\n",
    "comb_f = comb.loc[comb[\"combined_exposure\"] >= v].copy()\n",
    "\n",
    "# Rank neighbors per anchor\n",
    "comb_f = comb_f.sort_values(\n",
    "    by=[\n",
    "        \"anchor\",\n",
    "        \"combined_exposure\",\n",
    "        \"total_trade_with_anchor\",\n",
    "        \"export_share\",\n",
    "        \"import_share\",\n",
    "        \"COUNTRY\",\n",
    "    ],\n",
    "    ascending=[True, False, False, False, False, True],\n",
    ")\n",
    "\n",
    "# Rank within each anchor and take top n\n",
    "comb_f[\"rank_within_anchor\"] = comb_f.groupby(\"anchor\")[\"combined_exposure\"].rank(\n",
    "    method=\"first\", ascending=False\n",
    ")\n",
    "comb_top = comb_f.loc[comb_f[\"rank_within_anchor\"] <= n].copy()\n",
    "\n",
    "# Final neighbor\n",
    "neighbors_dict = comb_top.groupby(\"anchor\")[\"COUNTRY\"].apply(list).to_dict()\n",
    "\n",
    "# Summary results\n",
    "summary = (\n",
    "    comb_top[\n",
    "        [\n",
    "            \"anchor\",\n",
    "            \"COUNTRY\",\n",
    "            \"combined_exposure\",\n",
    "            \"export_share\",\n",
    "            \"import_share\",\n",
    "            \"export_to_anchor\",\n",
    "            \"import_from_anchor\",\n",
    "            \"export_total\",\n",
    "            \"import_total\",\n",
    "            \"total_trade_with_anchor\",\n",
    "            \"total_trade_volume\",\n",
    "            \"rank_within_anchor\",\n",
    "        ]\n",
    "    ]\n",
    "    .sort_values([\"anchor\", \"rank_within_anchor\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "res = summary.copy()\n",
    "for col in [\"combined_exposure\", \"export_share\", \"import_share\"]:\n",
    "    res[col] = (res[col] * 100).round(2)\n",
    "\n",
    "res_sorted = res.sort_values([\"anchor\", \"rank_within_anchor\"])\n",
    "anchor_neighbor = res_sorted.groupby(\"anchor\")[\"COUNTRY\"].apply(list).to_dict()\n",
    "\n",
    "for a, c in [(\"CNY\", \"Australia\"), (\"JPY\", \"Philippines\"), (\"JPY\", \"Vietnam\")]:\n",
    "    if a in anchor_neighbor and c in anchor_neighbor[a]:\n",
    "        anchor_neighbor[a].remove(c)\n",
    "\n",
    "anchor_neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee3e8c5",
   "metadata": {},
   "source": [
    "#### Principle Component Analysis (PCA)\n",
    "\n",
    "*Performing Principle Component Analysis (PCA) to reduce the dimensionality of our training data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1db890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We identify the hour anchor: Anchor = {\"EUR\": EUR, \"CNY\": {\"China\"}, \"JPY\": {\"Japan\"}}\n",
    "\n",
    "# Going to start by pulling Anchor Countries\n",
    "# Codes are obtain from yahoo finance symbol\n",
    "# https://finance.yahoo.com/markets/currencies/\n",
    "\n",
    "fx_list = {\n",
    "    # Anchor currencies\n",
    "    \"CNY\": \"CNY=X\",  # China\n",
    "    \"EUR\": \"EUR=X\",  # Euro\n",
    "    \"JPY\": \"JPY=X\",  # Japan\n",
    "    # Neutral currencies\n",
    "    \"CAD\": \"CAD=X\",  # Canada\n",
    "    \"BRL\": \"BRL=X\",  # Brazil\n",
    "    \"MXN\": \"MXN=X\",  # Mexico\n",
    "    \"COP\": \"COP=X\",  # Colombia\n",
    "    \"PEN\": \"PEN=X\",  # Peru\n",
    "    \"NOK\": \"NOK=X\",  # Norway\n",
    "    \"ZAR\": \"ZAR=X\",  # South Africa\n",
    "    \"INR\": \"INR=X\",  # India\n",
    "    \"TRY\": \"TRY=X\",  # Turkey\n",
    "    \"EGP\": \"EGP=X\",  # Egypt\n",
    "    \"RUB\": \"RUB=X\",  # Russia\n",
    "    \"ILS\": \"ILS=X\",  # Israel\n",
    "    # CNY group\n",
    "    \"CDF\": \"CDF=X\",  # DR Congo\n",
    "    \"LAK\": \"LAK=X\",  # Laos\n",
    "    \"TZS\": \"TZS=X\",  # Tanzania\n",
    "    \"CLP\": \"CLP=X\",  # Chile\n",
    "    \"GNF\": \"GNF=X\",  # Guinea\n",
    "    \"PKR\": \"PKR=X\",  # Pakistan\n",
    "    \"PHP\": \"PHP=X\",  # Philippines\n",
    "    \"VND\": \"VND=X\",  # Vietnam\n",
    "    \"MRU\": \"MRU=X\",  # Mauritania\n",
    "    # EUR group\n",
    "    \"ALL\": \"ALL=X\",  # Albania\n",
    "    \"CZK\": \"CZK=X\",  # Czechia\n",
    "    \"TND\": \"TND=X\",  # Tunisia\n",
    "    \"RON\": \"RON=X\",  # Romania\n",
    "    \"HUF\": \"HUF=X\",  # Hungary\n",
    "    \"PLN\": \"PLN=X\",  # Poland\n",
    "    \"RSD\": \"RSD=X\",  # Serbia\n",
    "    \"SEK\": \"SEK=X\",  # Sweden\n",
    "    \"ISK\": \"ISK=X\",  # Iceland\n",
    "    \"DZD\": \"DZD=X\",  # Algeria\n",
    "    # JPY group\n",
    "    \"PGK\": \"PGK=X\",  # Papua New Guinea\n",
    "    \"TWD\": \"TWD=X\",  # Taiwan\n",
    "    \"THB\": \"THB=X\",  # Thailand\n",
    "    \"AUD\": \"AUD=X\",  # Australia\n",
    "    \"IDR\": \"IDR=X\",  # Indonesia\n",
    "    \"KRW\": \"KRW=X\",  # South Korea\n",
    "    \"MYR\": \"MYR=X\",  # Malaysia\n",
    "    \"NZD\": \"NZD=X\",  # New Zealand\n",
    "}\n",
    "\n",
    "# Period is the timeframe we want, we conclude for the time being, it will be 10 years\n",
    "PERIOD = \"10y\"\n",
    "\n",
    "# We conclude we will be looking at exchanges on a daily basis.\n",
    "INTERVAL = \"1d\"\n",
    "FFill_Limit = 3\n",
    "N_PCS_To_Cluster = 3\n",
    "N_Cluster = 3\n",
    "\n",
    "# Creating a list of tickers from the fx_list dictionary\n",
    "tickers = list(fx_list.values())\n",
    "\n",
    "# Creating a DataFrame by downloading historical FX data using yfinance\n",
    "yfinance_fx_raw = yf.download(\n",
    "    tickers, period=PERIOD, interval=INTERVAL, auto_adjust=None, progress=False\n",
    ")\n",
    "\n",
    "# Remove problem currency\n",
    "x = yfinance_fx_raw[\"Close\"]\n",
    "c = x.notna().sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531f2021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove currencies that have less than 2000 data points\n",
    "want = list(fx_list.keys())\n",
    "t = []\n",
    "invert = {}\n",
    "\n",
    "# Loop through each currency in the want list and get their corresponding ticker symbols\n",
    "for c in want:\n",
    "    t1, t2 = xxxusd(c)\n",
    "    t.extend([t1, t2])\n",
    "\n",
    "# Remove duplicates while preserving order\n",
    "t = list(dict.fromkeys(t))\n",
    "\n",
    "# Creating a DataFrame by downloading historical FX data using yfinance\n",
    "raw = yf.download(\n",
    "    t, period=PERIOD, interval=INTERVAL, auto_adjust=None, progress=False\n",
    ")[\"Close\"]\n",
    "\n",
    "# Creating a DataFrame to hold exchange rate levels and whether they need to be inverted\n",
    "level = {}\n",
    "for c in want:\n",
    "    t1, t2 = xxxusd(c)\n",
    "    if t1 in raw.columns and raw[t1].notna().sum() > 0:\n",
    "        level[c] = raw[t1]\n",
    "        invert[c] = False\n",
    "    elif t2 in raw.columns and raw[t2].notna().sum() > 0:\n",
    "        level[c] = 1.0 / raw[t2]\n",
    "        invert[c] = True\n",
    "\n",
    "# Creating a DataFrame from the level dictionary and sorting by index\n",
    "level = pd.DataFrame(level).sort_index()\n",
    "\n",
    "# Calculating log returns and handling missing values\n",
    "lreturn = np.log(level / level.shift(1))\n",
    "lreturn = lreturn.ffill(limit=3).dropna(how=\"any\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd53ac3",
   "metadata": {},
   "source": [
    "#### Performing PCA and KMeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0238da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the log returns\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(\n",
    "    scaler.fit_transform(lreturn),\n",
    "    index=lreturn.index,\n",
    "    columns=lreturn.columns,\n",
    ")\n",
    "\n",
    "# PCA and KMeans Clustering\n",
    "pca = PCA(n_components=2)\n",
    "Z = pca.fit_transform(X.T)\n",
    "\n",
    "# Creating a DataFrame for PCA results\n",
    "pca_df = pd.DataFrame(Z, index=X.columns, columns=[\"PC1\", \"PC2\"])\n",
    "\n",
    "# KMeans Clustering\n",
    "k = 3\n",
    "km = KMeans(n_clusters=k, random_state=42)\n",
    "pca_df[\"cluster\"] = km.fit_predict(pca_df[[\"PC1\", \"PC2\"]].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c1db53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addidtional pull for explained_variance_ratio_\n",
    "evr = pca.explained_variance_ratio_\n",
    "print(\"Explained variance ratio: \", evr, \" | Cumalative: \", evr.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597912e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping currencies based on economic ties\n",
    "g = {\n",
    "    \"CNY\": [\"CDF\", \"LAK\", \"TZS\", \"CLP\", \"GNF\", \"PKR\", \"PHP\", \"VND\", \"MRU\"],\n",
    "    \"EUR\": [\"ALL\", \"CZK\", \"TND\", \"RON\", \"HUF\", \"PLN\", \"RSD\", \"SEK\", \"ISK\", \"DZD\"],\n",
    "    \"JPY\": [\"PGK\", \"TWD\", \"THB\", \"AUD\", \"IDR\", \"KRW\", \"MYR\", \"NZD\"],\n",
    "}\n",
    "\n",
    "\n",
    "# Function to assign group based on currency code\n",
    "def assign(cc):\n",
    "    for i, j in g.items():\n",
    "        if cc == i or cc in j:\n",
    "            return i\n",
    "    return \"other\"\n",
    "\n",
    "\n",
    "# Assigning group to each currency in the PCA DataFrame\n",
    "pca_df[\"group\"] = pca_df.index.map(assign)\n",
    "\n",
    "# Visualization of PCA Results\n",
    "col = {\"CNY\": \"red\", \"EUR\": \"blue\", \"INR\": \"green\", \"JPY\": \"orange\", \"other\": \"gray\"}\n",
    "plt.figure(figsize=(12, 8))\n",
    "for grp, sub in pca_df.groupby(\"group\"):\n",
    "    plt.scatter(\n",
    "        sub[\"PC1\"],\n",
    "        sub[\"PC2\"],\n",
    "        c=col.get(grp, \"black\"),\n",
    "        s=70,\n",
    "        alpha=0.85,\n",
    "        label=f\"{grp} (n={len(sub)})\",\n",
    "    )\n",
    "    for i, j in sub.iterrows():\n",
    "        plt.annotate(\n",
    "            i,\n",
    "            (j[\"PC1\"], j[\"PC2\"]),\n",
    "            xytext=(3, 3),\n",
    "            textcoords=\"offset points\",\n",
    "            fontsize=8,\n",
    "        )\n",
    "\n",
    "plt.title(\"Currencies in PCA Space (standardized returns, XXX/USD)\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59125e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Silhouette Score\n",
    "score = silhouette_score(pca_df[[\"PC1\", \"PC2\"]], pca_df[\"cluster\"])\n",
    "\n",
    "# Saving the log returns DataFrame to a Parquet file\n",
    "lreturn.to_parquet(\"fx_log_return.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08e4ed2",
   "metadata": {},
   "source": [
    "## Applying Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb239abd",
   "metadata": {},
   "source": [
    "#### File Checkpoint\n",
    "*During recreation of results - if up to this point importation of data has failed for any reason, the below `lreturn` should be a checkpoint. This checkpoint includes anchor neighbor pairings of data that have been \"pre-processed\" with K-means clustering and Principal Component Analysis.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7e27c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this if the above didn't work\n",
    "# This is a stashed checkpoint file\n",
    "lreturn = pd.read_parquet(\"../data/input/fx_log_return.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd90a84",
   "metadata": {},
   "source": [
    "#### Granger Causality\n",
    "\n",
    "*Applying granger causality test to determine if a causal realtionship is found in our anchor and neighboring currency returns*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8651123e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping currencies based on economic ties\n",
    "g = {\n",
    "    \"CNY\": [\"CDF\", \"LAK\", \"TZS\", \"CLP\", \"GNF\", \"PKR\", \"PHP\", \"VND\", \"MRU\"],\n",
    "    \"EUR\": [\"ALL\", \"CZK\", \"TND\", \"RON\", \"HUF\", \"PLN\", \"RSD\", \"SEK\", \"ISK\", \"DZD\"],\n",
    "    \"JPY\": [\"PGK\", \"TWD\", \"THB\", \"AUD\", \"IDR\", \"KRW\", \"MYR\", \"NZD\"],\n",
    "}\n",
    "\n",
    "rdf = granger(lreturn, g, 10, 0.05)\n",
    "rdf = rdf.sort_values([\"anchor\", \"min_pval\"]).reset_index(drop=True)\n",
    "an = rdf[rdf[\"significant\"] == True].sort_values([\"anchor\", \"min_pval\"])\n",
    "ng = an.groupby(\"anchor\")[\"neighbor\"].apply(list).to_dict()\n",
    "ng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de94c903",
   "metadata": {},
   "source": [
    "#### K Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3937654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter pairs\n",
    "pa = [(i, j) for i, nl in ng.items() for j in nl]\n",
    "\n",
    "# Preparing data for modeling\n",
    "res = {}\n",
    "\n",
    "# Loop through each anchor-neighbor pair to create lagged features and target variable\n",
    "for i, j in pa:\n",
    "    lag = int(rdf[(rdf.anchor == i) & (rdf.neighbor == j)][\"best_lag (days)\"].values[0])\n",
    "    f = lreturn[[i, j]].copy()\n",
    "    f = mlag(f, j, 3)\n",
    "    f = mlag(f, i, lag)\n",
    "    f[\"target\"] = f[j].shift(-1)\n",
    "    f = f.dropna()\n",
    "    res[(i, j)] = f\n",
    "\n",
    "# KNN\n",
    "# All pair check:\n",
    "# This includes all anchor and neighbors for knn\n",
    "resknn = []\n",
    "\n",
    "# Loop through each anchor-neighbor pair to train and evaluate KNN model\n",
    "for (i, j), df_0 in res.items():\n",
    "    features = [col for col in df_0.columns if col not in [\"target\"]]\n",
    "    X = df_0[features]\n",
    "    y = df_0[\"target\"]\n",
    "    split_index = int(len(X) * 0.8)\n",
    "    X_train, X_test = X[:split_index], X[split_index:]\n",
    "    y_train, y_test = y[:split_index], y[split_index:]\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    model = KNeighborsRegressor(n_neighbors=5, weights=\"distance\")\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    rmse = root_mean_squared_error(y_test, y_pred)\n",
    "    resknn.append({\"anchor\": i, \"neighbor\": j, \"rmse\": rmse})\n",
    "\n",
    "# Creating a DataFrame from the KNN results and sorting by RMSE\n",
    "knn = pd.DataFrame(resknn).sort_values(\"rmse\").reset_index(drop=True)\n",
    "knn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeec0ed1",
   "metadata": {},
   "source": [
    "#### Linear Regression\n",
    "\n",
    "*Utilizing a linear family model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bf6bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "neighbor_groups, df_anchor_neighor, df_log_return_pca = load_data()\n",
    "\n",
    "# Compiling scores\n",
    "final = []\n",
    "\n",
    "# Running LR for each anchor neighbor pair\n",
    "for option in [\"Training_with_Anchor\", \"Training_without_Anchor\"]:\n",
    "\n",
    "    for i, j in zip(df_anchor_neighor[\"anchor\"], df_anchor_neighor[\"neighbor\"]):\n",
    "\n",
    "        # Initializing dictionary to hold scores\n",
    "        scores = {}\n",
    "\n",
    "        # Preparing data for train test split\n",
    "        df_1 = df_log_return_pca[[i, j]]\n",
    "        df_1 = df_1.drop(columns=[i])\n",
    "        df_1 = create_lag(j, df_1)\n",
    "\n",
    "        # Time-based train-test split\n",
    "        df_1[\"target\"] = df_1[j].shift(-1)\n",
    "        df_1.dropna(inplace=True)\n",
    "\n",
    "        # Define features (X) and target (y)\n",
    "        if option == \"Training_without_Anchor\":\n",
    "            features = [col for col in df_1.columns]\n",
    "            i = None\n",
    "        else:\n",
    "            features = [\n",
    "                col\n",
    "                for col in df_1.columns\n",
    "                if col == j or col.startswith(\"MA_\") or col.startswith(\"return_lag_\")\n",
    "            ]\n",
    "\n",
    "        X = df_1[features]\n",
    "        y = df_1[\"target\"]\n",
    "\n",
    "        # Splitting data into train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "        clf_lr = LinearRegression().fit(X, y)\n",
    "        y_preds = clf_lr.predict(X_test)\n",
    "\n",
    "        # Assigning scores\n",
    "        scores[\"anchor\"] = i\n",
    "        scores[\"neighbor\"] = j\n",
    "        scores[\"option\"] = option\n",
    "        # scores['rmse'] = root_mean_squared_error(y_test, y_preds)\n",
    "        scores[\"rmse\"] = np.mean(\n",
    "            np.sqrt(\n",
    "                np.abs(\n",
    "                    cross_val_score(\n",
    "                        clf_lr, X, y, scoring=\"neg_mean_squared_error\", cv=5, n_jobs=-1\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        scores[\"model\"] = \"Linear Regression\"\n",
    "        scores[\"params\"] = None\n",
    "\n",
    "        # print(scores)\n",
    "        final.append(scores)\n",
    "\n",
    "# Organizing results\n",
    "df_final = pd.DataFrame(final)\n",
    "df_final_summary_mean = df_final.groupby(\"option\")[\"rmse\"].mean()\n",
    "df_final_summary_std = df_final.groupby(\"option\")[\"rmse\"].std()\n",
    "\n",
    "# # Printing results\n",
    "df_final\n",
    "df_final_summary_mean, df_final_summary_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd07952",
   "metadata": {},
   "source": [
    "#### Extreme Gradient Boosted Regression (XGBoost)\n",
    "\n",
    "*Utlizing a tree family model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feb29c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "neighbor_groups, df_anchor_neighor, df_log_return_pca = load_data()\n",
    "\n",
    "# Compiling scores\n",
    "final = []\n",
    "\n",
    "# Running LR for each anchor neighbor pair\n",
    "for option in [\"Training_with_Anchor\", \"Training_without_Anchor\"]:\n",
    "\n",
    "    for i, j in zip(df_anchor_neighor[\"anchor\"], df_anchor_neighor[\"neighbor\"]):\n",
    "\n",
    "        # Initializing dictionary to hold scores\n",
    "        scores = {}\n",
    "\n",
    "        # Preparing data for train test split\n",
    "        df_1 = df_log_return_pca[[i, j]]\n",
    "        df_1 = df_1.drop(columns=[i])\n",
    "        df_1 = create_lag(j, df_1)\n",
    "\n",
    "        # Time-based train-test split\n",
    "        df_1[\"target\"] = df_1[j].shift(-1)\n",
    "        df_1.dropna(inplace=True)\n",
    "\n",
    "        # Define features (X) and target (y)\n",
    "        if option == \"Training_without_Anchor\":\n",
    "            features = [col for col in df_1.columns]\n",
    "            i = None\n",
    "        else:\n",
    "            features = [\n",
    "                col\n",
    "                for col in df_1.columns\n",
    "                if col == j or col.startswith(\"MA_\") or col.startswith(\"return_lag_\")\n",
    "            ]\n",
    "\n",
    "        X = df_1[features]\n",
    "        y = df_1[\"target\"]\n",
    "\n",
    "        # Preparing data for train test split\n",
    "        df_1 = df_log_return_pca[[i, j]]\n",
    "        df_1.dropna(inplace=True)\n",
    "        df_1 = create_lag(j, df_1).drop(columns=[i])\n",
    "        score, params, y_preds = perform_xgb_for_anchor_neighbor(j, df_1)\n",
    "\n",
    "        # Assigning scores\n",
    "        scores[\"anchor\"] = i\n",
    "        scores[\"neighbor\"] = j\n",
    "        scores[\"option\"] = option\n",
    "        scores[\"rmse\"] = np.mean(\n",
    "            np.sqrt(\n",
    "                np.abs(\n",
    "                    cross_val_score(\n",
    "                        xgb.XGBRegressor(**params),\n",
    "                        X,\n",
    "                        y,\n",
    "                        scoring=\"neg_mean_squared_error\",\n",
    "                        cv=5,\n",
    "                        n_jobs=-1,\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        scores[\"model\"] = \"XGBoost\"\n",
    "        scores[\"params\"] = None\n",
    "\n",
    "        # print(scores)\n",
    "        final.append(scores)\n",
    "\n",
    "# Organizing final results\n",
    "df_final = pd.DataFrame(final)\n",
    "df_final_summary_mean = df_final.groupby(\"option\")[\"rmse\"].mean()\n",
    "df_final_summary_std = df_final.groupby(\"option\")[\"rmse\"].std()\n",
    "\n",
    "# Printing final results\n",
    "print(df_final)\n",
    "print(df_final_summary_mean)\n",
    "print(df_final_summary_std)\n",
    "\n",
    "# Printing delta between with and without training anchor\n",
    "print(\n",
    "    rf\"Difference without anchor: {df_final_summary_mean[0] - df_final_summary_mean[1]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d84dd0b",
   "metadata": {},
   "source": [
    "## Testing Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae99a1b",
   "metadata": {},
   "source": [
    "#### Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b271724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "neighbor_groups, df_anchor_neighor, df_log_return_pca = load_data()\n",
    "\n",
    "# Compiling scores\n",
    "final = []\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "# Preparing data for train test split\n",
    "df_1 = df_log_return_pca\n",
    "\n",
    "# List of features to ablate\n",
    "ls_1 = [\n",
    "    \"return_lag_1\",\n",
    "    \"return_lag_2\",\n",
    "    \"return_lag_3\",\n",
    "    \"return_lag_4\",\n",
    "    \"return_lag_5\",\n",
    "    \"return_lag_6\",\n",
    "    \"return_lag_7\",\n",
    "    \"return_lag_8\",\n",
    "    \"return_lag_9\",\n",
    "    \"return_lag_10\",\n",
    "    \"return_lag_11\",\n",
    "    \"return_lag_12\",\n",
    "    \"return_lag_13\",\n",
    "    \"return_lag_14\",\n",
    "    \"return_lag_15\",\n",
    "    \"return_lag_16\",\n",
    "    \"return_lag_17\",\n",
    "    \"return_lag_18\",\n",
    "    \"return_lag_19\",\n",
    "    \"return_lag_20\",\n",
    "    \"return_lag_21\",\n",
    "    \"return_lag_22\",\n",
    "    \"return_lag_23\",\n",
    "    \"return_lag_24\",\n",
    "    \"MA_30\",\n",
    "    \"MA_60\",\n",
    "    \"MA_90\",\n",
    "]\n",
    "\n",
    "for ablated in ls_1:\n",
    "\n",
    "    # Looping through each anchor-neighbor pair\n",
    "    for i, j in zip(df_anchor_neighor[\"anchor\"], df_anchor_neighor[\"neighbor\"]):\n",
    "        # Initializing dictionary to hold scores\n",
    "        scores = {}\n",
    "\n",
    "        # Preparing data for train test split\n",
    "        df_1 = df_log_return_pca[[i, j]]\n",
    "        df_1 = df_1.drop(columns=[i])\n",
    "        df_1 = create_lag(j, df_1)\n",
    "\n",
    "        ls_0 = list(df_1.columns)\n",
    "        ls_0.remove(str(ablated))\n",
    "        df_1 = df_1[ls_0]\n",
    "\n",
    "        # Time-based train-test split\n",
    "        df_1[\"target\"] = df_1[j].shift(-1)\n",
    "        df_1.dropna(inplace=True)\n",
    "\n",
    "        for option in [\"Training_with_Anchor\", \"Training_without_Anchor\"]:\n",
    "\n",
    "            # Define features (X) and target (y)\n",
    "            if option == \"Training_without_Anchor\":\n",
    "                features = [col for col in df_1.columns]\n",
    "                i = None\n",
    "            else:\n",
    "                features = [\n",
    "                    col\n",
    "                    for col in df_1.columns\n",
    "                    if col == j\n",
    "                    or col.startswith(\"MA_\")\n",
    "                    or col.startswith(\"return_lag_\")\n",
    "                ]\n",
    "\n",
    "            X = df_1[features]\n",
    "            y = df_1[\"target\"]\n",
    "\n",
    "            # Splitting data into train and test sets\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=0.2, random_state=42\n",
    "            )\n",
    "            clf_lr = LinearRegression().fit(X, y)\n",
    "            y_preds = clf_lr.predict(X_test)\n",
    "\n",
    "            # Assigning scores\n",
    "            scores[\"anchor\"] = i\n",
    "            scores[\"neighbor\"] = j\n",
    "            scores[\"option\"] = option\n",
    "            # scores['rmse'] = root_mean_squared_error(y_test, y_preds)\n",
    "            scores[\"rmse\"] = np.mean(\n",
    "                np.sqrt(\n",
    "                    np.abs(\n",
    "                        cross_val_score(\n",
    "                            clf_lr,\n",
    "                            X,\n",
    "                            y,\n",
    "                            scoring=\"neg_mean_squared_error\",\n",
    "                            cv=5,\n",
    "                            n_jobs=-1,\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            scores[\"model\"] = \"Linear Regression\"\n",
    "            scores[\"params\"] = None\n",
    "            scores[\"ablated_feature\"] = ablated\n",
    "            final.append(scores)\n",
    "\n",
    "        final_df = pd.concat([final_df, pd.DataFrame(final)], ignore_index=True)\n",
    "\n",
    "final_df.drop_duplicates().to_csv(\n",
    "    \"../data/output/ablation_study_lr_results.csv\", sep=\"|\", index=False\n",
    ")\n",
    "\n",
    "# final_df_summary_mean = final_df.groupby([\"option\", \"ablated_feature\"])[\"rmse\"].mean()\n",
    "# final_df_summary_std = final_df.groupby([\"option\", \"ablated_feature\"])[\"rmse\"].std()\n",
    "df_summary = (\n",
    "    pd.DataFrame(\n",
    "        final_df.drop_duplicates()[[\"ablated_feature\", \"rmse\"]]\n",
    "        .groupby([\"ablated_feature\"])[\"rmse\"]\n",
    "        .mean()\n",
    "    )\n",
    "    .reset_index(drop=False)\n",
    "    .sort_values(by=[\"rmse\"], ascending=True)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "df_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a010a6f",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768c0cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "neighbor_groups, df_anchor_neighor, df_log_return_pca = load_data()\n",
    "\n",
    "# Compiling scores\n",
    "final = []\n",
    "\n",
    "# Running LR for each anchor neighbor pair\n",
    "for option in [\"Training_with_Anchor\", \"Training_without_Anchor\"]:\n",
    "\n",
    "    for i, j in zip(df_anchor_neighor[\"anchor\"], df_anchor_neighor[\"neighbor\"]):\n",
    "\n",
    "        # Initializing dictionary to hold scores\n",
    "        scores = pd.DataFrame()\n",
    "\n",
    "        # Preparing data for train test split\n",
    "        df_1 = df_log_return_pca[[i, j]]\n",
    "        df_1 = df_1.drop(columns=[i])\n",
    "        df_1 = create_lag(j, df_1)\n",
    "\n",
    "        # Time-based train-test split\n",
    "        df_1[\"target\"] = df_1[j].shift(-1)\n",
    "        df_1.dropna(inplace=True)\n",
    "\n",
    "        # Define features (X) and target (y)\n",
    "        if option == \"Training_without_Anchor\":\n",
    "            features = [col for col in df_1.columns]\n",
    "            i = None\n",
    "        else:\n",
    "            features = [\n",
    "                col\n",
    "                for col in df_1.columns\n",
    "                if col == j or col.startswith(\"MA_\") or col.startswith(\"return_lag_\")\n",
    "            ]\n",
    "\n",
    "        X = df_1[features]\n",
    "        y = df_1[\"target\"]\n",
    "\n",
    "        # Splitting data into train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "        clf_lr = LinearRegression().fit(X, y)\n",
    "        y_preds = clf_lr.predict(X_test)\n",
    "\n",
    "        # Assigning scores\n",
    "        scores[\"features\"] = features\n",
    "        scores[\"importance\"] = clf_lr.coef_\n",
    "        # print(scores)\n",
    "\n",
    "        # print(scores)\n",
    "        final.append(scores)\n",
    "\n",
    "df_final = pd.concat(final, ignore_index=True)\n",
    "df_summary = pd.DataFrame(\n",
    "    df_final.groupby(\"features\")[\"importance\"].mean()\n",
    ").reset_index(drop=False)\n",
    "df_summary = (\n",
    "    df_summary[df_summary[\"features\"].isin(ls_1)]\n",
    "    .sort_values(by=\"importance\", ascending=True)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "df_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cb1868",
   "metadata": {},
   "source": [
    "#### Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d5c987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "neighbor_groups, df_anchor_neighor, df_log_return_pca = load_data()\n",
    "\n",
    "# Compiling scores\n",
    "final = []\n",
    "\n",
    "# Running LR for each anchor neighbor pair\n",
    "for option in [\"Training_with_Anchor\", \"Training_without_Anchor\"]:\n",
    "\n",
    "    for i, j in zip(df_anchor_neighor[\"anchor\"], df_anchor_neighor[\"neighbor\"]):\n",
    "\n",
    "        # Initializing dictionary to hold scores\n",
    "        scores = {}\n",
    "\n",
    "        # Preparing data for train test split\n",
    "        df_1 = df_log_return_pca[[i, j]]\n",
    "        df_1 = df_1.drop(columns=[i])\n",
    "        df_1 = create_lag(j, df_1)\n",
    "\n",
    "        # Time-based train-test split\n",
    "        df_1[\"target\"] = df_1[j].shift(-1)\n",
    "        df_1.dropna(inplace=True)\n",
    "\n",
    "        # Define features (X) and target (y)\n",
    "        if option == \"Training_without_Anchor\":\n",
    "            features = [col for col in df_1.columns]\n",
    "            i = None\n",
    "        else:\n",
    "            features = [\n",
    "                col\n",
    "                for col in df_1.columns\n",
    "                if col == j or col.startswith(\"MA_\") or col.startswith(\"return_lag_\")\n",
    "            ]\n",
    "\n",
    "        X = df_1[features]\n",
    "        y = df_1[\"target\"]\n",
    "\n",
    "        # Splitting data into train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "        clf_lr = LinearRegression().fit(X, y)\n",
    "        clf_lr.set_params(copy_X=False, fit_intercept=False, n_jobs=-1, positive=True)\n",
    "        y_preds = clf_lr.predict(X_test)\n",
    "\n",
    "        # Assigning scores\n",
    "        scores[\"anchor\"] = i\n",
    "        scores[\"neighbor\"] = j\n",
    "        scores[\"option\"] = option\n",
    "        # scores['rmse'] = root_mean_squared_error(y_test, y_preds)\n",
    "        scores[\"rmse\"] = np.mean(\n",
    "            np.sqrt(\n",
    "                np.abs(\n",
    "                    cross_val_score(\n",
    "                        clf_lr, X, y, scoring=\"neg_mean_squared_error\", cv=5, n_jobs=-1\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        scores[\"model\"] = \"Linear Regression\"\n",
    "        scores[\"params\"] = None\n",
    "\n",
    "        # print(scores)\n",
    "        final.append(scores)\n",
    "\n",
    "# Organizing results\n",
    "df_final = pd.DataFrame(final)\n",
    "df_final_summary_mean = df_final.groupby(\"option\")[\"rmse\"].mean()\n",
    "df_final_summary_std = df_final.groupby(\"option\")[\"rmse\"].std()\n",
    "\n",
    "# Printing results\n",
    "print(\n",
    "    \"Mean RMSE and standard deviation RMSE (in that order) - without hyperparameter tuning\"\n",
    "    \"\"\"\n",
    " option\n",
    " Training_with_Anchor       6.801129e-03\n",
    " Training_without_Anchor    8.939379e-15\n",
    " Name: rmse, dtype: float64,\n",
    " option\n",
    " Training_with_Anchor       2.559958e-03\n",
    " Training_without_Anchor    5.607145e-15\n",
    " Name: rmse, dtype: float64)\"\"\"\n",
    ")\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\n",
    "    \"Mean RMSE and standard deviation RMSE (in that order) - with hyperparameter tuning\"\n",
    ")\n",
    "print(df_final_summary_mean)\n",
    "print(df_final_summary_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89678b28",
   "metadata": {},
   "source": [
    "#### Failure Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cb4dddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>actuals</th>\n",
       "      <th>target</th>\n",
       "      <th>option</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4012</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.063</td>\n",
       "      <td>TND</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3976</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.060</td>\n",
       "      <td>TND</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.060</td>\n",
       "      <td>TND</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>-0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.063</td>\n",
       "      <td>TND</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>-0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4005</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.060</td>\n",
       "      <td>TND</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.060</td>\n",
       "      <td>TND</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>-0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3968</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.055</td>\n",
       "      <td>TND</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.055</td>\n",
       "      <td>TND</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>-0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3814</th>\n",
       "      <td>-0.039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>CZK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3359</th>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.010</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3368</th>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.001</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3346</th>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.005</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3379</th>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6385</th>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.003</td>\n",
       "      <td>PLN</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6346</th>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>PLN</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.006</td>\n",
       "      <td>0.023</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>-0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.019</td>\n",
       "      <td>TND</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>-0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5356</th>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.001</td>\n",
       "      <td>HUF</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.005</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>-0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4021</th>\n",
       "      <td>0.004</td>\n",
       "      <td>0.019</td>\n",
       "      <td>TND</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4671</th>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.005</td>\n",
       "      <td>RSD</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3362</th>\n",
       "      <td>0.007</td>\n",
       "      <td>0.023</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5685</th>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.004</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>TND</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>-0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5342</th>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.007</td>\n",
       "      <td>HUF</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3347</th>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.002</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3822</th>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.005</td>\n",
       "      <td>CZK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5203</th>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.004</td>\n",
       "      <td>HUF</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5394</th>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>HUF</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.000</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3775</th>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>CZK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.010</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>-0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6240</th>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>PLN</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5737</th>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.001</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6423</th>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>PLN</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6232</th>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.005</td>\n",
       "      <td>PLN</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4189</th>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.003</td>\n",
       "      <td>RON</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5889</th>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.005</td>\n",
       "      <td>ISK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.004</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>-0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5546</th>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.005</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5211</th>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>HUF</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>-0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5554</th>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3849</th>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.001</td>\n",
       "      <td>CZK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388</th>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>HUF</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3661</th>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.004</td>\n",
       "      <td>CZK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6196</th>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.002</td>\n",
       "      <td>PLN</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>ALL</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6042</th>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>ISK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>-0.010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      predictions  actuals target                   option   diff\n",
       "4012        0.002    0.063    TND  Training_without_Anchor -0.061\n",
       "3976        0.000    0.060    TND  Training_without_Anchor -0.060\n",
       "792        -0.000    0.060    TND     Training_with_Anchor -0.060\n",
       "799         0.003    0.063    TND     Training_with_Anchor -0.060\n",
       "4005        0.001    0.060    TND  Training_without_Anchor -0.059\n",
       "763         0.003    0.060    TND     Training_with_Anchor -0.057\n",
       "3968        0.000    0.055    TND  Training_without_Anchor -0.055\n",
       "755         0.002    0.055    TND     Training_with_Anchor -0.053\n",
       "3814       -0.039    0.000    CZK  Training_without_Anchor -0.039\n",
       "3359       -0.018    0.010    ALL  Training_without_Anchor -0.028\n",
       "3368       -0.023    0.001    ALL  Training_without_Anchor -0.024\n",
       "3346       -0.016    0.005    ALL  Training_without_Anchor -0.021\n",
       "3379       -0.020   -0.002    ALL  Training_without_Anchor -0.018\n",
       "6385       -0.014    0.003    PLN  Training_without_Anchor -0.018\n",
       "6346       -0.017   -0.000    PLN  Training_without_Anchor -0.017\n",
       "149         0.006    0.023    ALL     Training_with_Anchor -0.017\n",
       "808         0.002    0.019    TND     Training_with_Anchor -0.017\n",
       "5356       -0.016    0.001    HUF  Training_without_Anchor -0.017\n",
       "133        -0.011    0.005    ALL     Training_with_Anchor -0.016\n",
       "4021        0.004    0.019    TND  Training_without_Anchor -0.015\n",
       "4671       -0.011    0.005    RSD  Training_without_Anchor -0.015\n",
       "3362        0.007    0.023    ALL  Training_without_Anchor -0.015\n",
       "5685       -0.010    0.004    SEK  Training_without_Anchor -0.015\n",
       "810        -0.018   -0.003    TND     Training_with_Anchor -0.015\n",
       "5342       -0.008    0.007    HUF  Training_without_Anchor -0.015\n",
       "3347       -0.012    0.002    ALL  Training_without_Anchor -0.015\n",
       "3822       -0.009    0.005    CZK  Training_without_Anchor -0.014\n",
       "5203       -0.010    0.004    HUF  Training_without_Anchor -0.014\n",
       "5394       -0.016   -0.002    HUF  Training_without_Anchor -0.013\n",
       "5734       -0.013    0.000    SEK  Training_without_Anchor -0.013\n",
       "5563       -0.014   -0.001    SEK  Training_without_Anchor -0.013\n",
       "3775       -0.015   -0.002    CZK  Training_without_Anchor -0.013\n",
       "146        -0.002    0.010    ALL     Training_with_Anchor -0.013\n",
       "6240       -0.014   -0.002    PLN  Training_without_Anchor -0.012\n",
       "5737       -0.011    0.001    SEK  Training_without_Anchor -0.012\n",
       "6423       -0.015   -0.003    PLN  Training_without_Anchor -0.012\n",
       "6232       -0.007    0.005    PLN  Training_without_Anchor -0.012\n",
       "4189       -0.008    0.003    RON  Training_without_Anchor -0.011\n",
       "5889       -0.006    0.005    ISK  Training_without_Anchor -0.011\n",
       "288        -0.007    0.004    ALL     Training_with_Anchor -0.011\n",
       "5546       -0.006    0.005    SEK  Training_without_Anchor -0.011\n",
       "5211       -0.017   -0.006    HUF  Training_without_Anchor -0.011\n",
       "293        -0.012   -0.001    ALL     Training_with_Anchor -0.011\n",
       "5554       -0.013   -0.002    SEK  Training_without_Anchor -0.010\n",
       "3849       -0.009    0.001    CZK  Training_without_Anchor -0.010\n",
       "5388       -0.005    0.005    HUF  Training_without_Anchor -0.010\n",
       "3661       -0.006    0.004    CZK  Training_without_Anchor -0.010\n",
       "6196       -0.007    0.002    PLN  Training_without_Anchor -0.010\n",
       "3466       -0.014   -0.004    ALL  Training_without_Anchor -0.010\n",
       "6042       -0.009    0.000    ISK  Training_without_Anchor -0.010"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing data\n",
    "neighbor_groups, df_anchor_neighor, df_log_return_pca = load_data()\n",
    "\n",
    "# Compiling scores\n",
    "final = []\n",
    "\n",
    "# Running LR for each anchor neighbor pair\n",
    "for option in [\"Training_with_Anchor\", \"Training_without_Anchor\"]:\n",
    "\n",
    "    for i, j in zip(df_anchor_neighor[\"anchor\"], df_anchor_neighor[\"neighbor\"]):\n",
    "\n",
    "        # Initializing dictionary to hold scores\n",
    "        scores = pd.DataFrame()\n",
    "\n",
    "        # Preparing data for train test split\n",
    "        df_1 = df_log_return_pca[[i, j]]\n",
    "        df_1 = df_1.drop(columns=[i])\n",
    "        df_1 = create_lag(j, df_1)\n",
    "\n",
    "        # Time-based train-test split\n",
    "        df_1[\"target\"] = df_1[j].shift(-1)\n",
    "        df_1.dropna(inplace=True)\n",
    "\n",
    "        # Define features (X) and target (y)\n",
    "        if option == \"Training_without_Anchor\":\n",
    "            features = [col for col in df_1.columns]\n",
    "            i = None\n",
    "        else:\n",
    "            features = [\n",
    "                col\n",
    "                for col in df_1.columns\n",
    "                if col == j or col.startswith(\"MA_\") or col.startswith(\"return_lag_\")\n",
    "            ]\n",
    "\n",
    "        X = df_1[features]\n",
    "        y = df_1[\"target\"]\n",
    "\n",
    "        # Splitting data into train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "        clf_lr = LinearRegression().fit(X, y)\n",
    "        y_preds = clf_lr.predict(X_test)\n",
    "\n",
    "        # Assigning scores\n",
    "        scores[\"predictions\"] = y_preds\n",
    "        scores[\"actuals\"] = y_test\n",
    "        scores[\"target\"] = j\n",
    "        scores[\"option\"] = option\n",
    "\n",
    "        # print(scores)\n",
    "        final.append(scores)\n",
    "\n",
    "        # Failure Analysis - Example 2\n",
    "        # print(j)\n",
    "        # ValidationCurveDisplay.from_estimator(\n",
    "        #     LinearRegression(), X, y, param_name=\"n_jobs\", param_range=[-1, 0, 5, 10]\n",
    "        # )\n",
    "\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x)\n",
    "df_final = pd.concat(final, ignore_index=True)\n",
    "df_final[\"diff\"] = df_final[\"predictions\"] - df_final[\"actuals\"]\n",
    "df_final.sort_values(by=[\"diff\"], ascending=True).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfff369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>actuals</th>\n",
       "      <th>target</th>\n",
       "      <th>option</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5622</th>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5530</th>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5660</th>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5531</th>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5699</th>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5611</th>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5586</th>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5588</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5538</th>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2303</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5675</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.003</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5697</th>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2409</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2444</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2373</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5690</th>\n",
       "      <td>0.007</td>\n",
       "      <td>0.001</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5610</th>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2318</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5686</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5672</th>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2325</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5657</th>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2317</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5594</th>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2289</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5602</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2459</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2389</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5517</th>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726</th>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2458</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5628</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_without_Anchor</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2350</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2352</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2297</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>SEK</td>\n",
       "      <td>Training_with_Anchor</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      predictions  actuals target                   option  diff\n",
       "5622        0.027   -0.006    SEK  Training_without_Anchor 0.033\n",
       "5530        0.017   -0.002    SEK  Training_without_Anchor 0.019\n",
       "2486        0.000   -0.018    SEK     Training_with_Anchor 0.018\n",
       "5660        0.015   -0.001    SEK  Training_without_Anchor 0.016\n",
       "5531        0.009   -0.004    SEK  Training_without_Anchor 0.013\n",
       "5699       -0.009   -0.018    SEK  Training_without_Anchor 0.009\n",
       "5611        0.004   -0.004    SEK  Training_without_Anchor 0.009\n",
       "2375        0.000   -0.009    SEK     Training_with_Anchor 0.009\n",
       "5586        0.003   -0.006    SEK  Training_without_Anchor 0.009\n",
       "5588       -0.000   -0.009    SEK  Training_without_Anchor 0.008\n",
       "5538        0.006   -0.002    SEK  Training_without_Anchor 0.008\n",
       "2303        0.000   -0.007    SEK     Training_with_Anchor 0.007\n",
       "5675        0.010    0.003    SEK  Training_without_Anchor 0.007\n",
       "2398        0.002   -0.004    SEK     Training_with_Anchor 0.007\n",
       "5697        0.004   -0.002    SEK  Training_without_Anchor 0.006\n",
       "2409       -0.000   -0.006    SEK     Training_with_Anchor 0.006\n",
       "2444       -0.000   -0.006    SEK     Training_with_Anchor 0.006\n",
       "2381        0.000   -0.006    SEK     Training_with_Anchor 0.006\n",
       "2373       -0.000   -0.006    SEK     Training_with_Anchor 0.006\n",
       "2306       -0.000   -0.006    SEK     Training_with_Anchor 0.006\n",
       "5690        0.007    0.001    SEK  Training_without_Anchor 0.005\n",
       "2397       -0.000   -0.006    SEK     Training_with_Anchor 0.005\n",
       "2473        0.001   -0.004    SEK     Training_with_Anchor 0.005\n",
       "5610       -0.001   -0.006    SEK  Training_without_Anchor 0.005\n",
       "2318        0.000   -0.004    SEK     Training_with_Anchor 0.004\n",
       "5686       -0.000   -0.004    SEK  Training_without_Anchor 0.004\n",
       "2513       -0.000   -0.004    SEK     Training_with_Anchor 0.004\n",
       "2323        0.000   -0.004    SEK     Training_with_Anchor 0.004\n",
       "2518       -0.000   -0.004    SEK     Training_with_Anchor 0.004\n",
       "2341        0.000   -0.002    SEK     Training_with_Anchor 0.003\n",
       "5672        0.001   -0.002    SEK  Training_without_Anchor 0.002\n",
       "2325        0.000   -0.002    SEK     Training_with_Anchor 0.002\n",
       "5657       -0.004   -0.006    SEK  Training_without_Anchor 0.002\n",
       "2317       -0.000   -0.002    SEK     Training_with_Anchor 0.002\n",
       "2447        0.001   -0.001    SEK     Training_with_Anchor 0.002\n",
       "5594       -0.004   -0.006    SEK  Training_without_Anchor 0.002\n",
       "2484       -0.000   -0.002    SEK     Training_with_Anchor 0.002\n",
       "5724        0.002    0.000    SEK  Training_without_Anchor 0.002\n",
       "2289        0.003    0.001    SEK     Training_with_Anchor 0.002\n",
       "5602       -0.000   -0.002    SEK  Training_without_Anchor 0.002\n",
       "2459        0.000   -0.002    SEK     Training_with_Anchor 0.002\n",
       "2389       -0.000   -0.002    SEK     Training_with_Anchor 0.002\n",
       "5517        0.001   -0.000    SEK  Training_without_Anchor 0.002\n",
       "5726       -0.003   -0.004    SEK  Training_without_Anchor 0.001\n",
       "2458        0.000   -0.001    SEK     Training_with_Anchor 0.001\n",
       "5628        0.005    0.004    SEK  Training_without_Anchor 0.001\n",
       "5565        0.000   -0.001    SEK  Training_without_Anchor 0.001\n",
       "2350        0.000   -0.001    SEK     Training_with_Anchor 0.001\n",
       "2352       -0.000   -0.001    SEK     Training_with_Anchor 0.001\n",
       "2297       -0.000   -0.001    SEK     Training_with_Anchor 0.001"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1\n",
    "# df_final[df_final['target'] == 'SEK'].dropna().sort_values(by=['diff'], ascending=False).head(50)\n",
    "\n",
    "# Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31a538c",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f60999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See final report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571872ce",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afa867e",
   "metadata": {},
   "source": [
    "We cannot confidently reject the null hypothesis that there is in fact no relationship between anchoring and neighboring countries in the prediciton of foreign exchange rates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
